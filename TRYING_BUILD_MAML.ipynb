{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM30NZ53Jp36DynKtmGDVva"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJUbKYfNxG3Q",
        "outputId": "6ceb0857-4b54-4778-a6f6-0c1f021922b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import Omniglot\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "hKZFPkCOyO5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "P4LpKMY3yRLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(1 * 11025, 64)\n",
        "        self.fc2 = nn.Linear(64, 5)  # 5 classes for Omniglot\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "sLZIH6OuyTVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68YU_f6OwllN"
      },
      "outputs": [],
      "source": [
        "# Define MAML class\n",
        "class MAML:\n",
        "    def __init__(self, model, inner_lr=0.01, meta_lr=0.001, num_classes=5):\n",
        "        self.model = model.to(device)\n",
        "        self.inner_lr = inner_lr\n",
        "        self.meta_lr = meta_lr\n",
        "        self.num_classes = num_classes\n",
        "        self.meta_optimizer = optim.Adam(self.model.parameters(), lr=meta_lr)\n",
        "\n",
        "    def inner_update(self, model, loss, step_size):\n",
        "        grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
        "        updated_model = self._update_parameters(model, grads, step_size)\n",
        "        return updated_model\n",
        "\n",
        "    def _update_parameters(self, model, grads, step_size):\n",
        "        updated_model = model\n",
        "        params = list(model.parameters())\n",
        "        for i in range(len(params)):\n",
        "            updated_model.param()[i] = params[i] - step_size * grads[i]\n",
        "        return updated_model\n",
        "\n",
        "    def meta_update(self, batch, K=5, N=5):\n",
        "        meta_loss = 0.0\n",
        "        for _ in range(N):\n",
        "            model_copy = SimpleModel().to(device)\n",
        "            model_copy.load_state_dict(self.model.state_dict())\n",
        "\n",
        "            inner_optimizer = optim.SGD(model_copy.parameters(), lr=self.inner_lr)\n",
        "\n",
        "            for _ in range(K):\n",
        "                inner_optimizer.zero_grad()\n",
        "                x, y = batch\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                logits = model_copy(x)\n",
        "\n",
        "                # Reshape y to match the logits shape\n",
        "                y = y.view(-1)\n",
        "\n",
        "                loss = nn.CrossEntropyLoss()(logits, y)\n",
        "                model_copy = self.inner_update(model_copy, loss, self.inner_lr)\n",
        "\n",
        "            logits = model_copy(x)\n",
        "            loss = nn.CrossEntropyLoss()(logits, y)\n",
        "            meta_loss += loss\n",
        "\n",
        "        meta_loss /= N\n",
        "\n",
        "        self.meta_optimizer.zero_grad()\n",
        "        meta_loss.backward()\n",
        "        self.meta_optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(self, dataloader, epochs=5, K=5, N=5):\n",
        "        for epoch in range(epochs):\n",
        "            for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n",
        "                inputs, targets = batch\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                # Convert targets to one-hot encoding\n",
        "                targets_onehot = torch.zeros(targets.size(0), self.num_classes).to(device)\n",
        "                targets_onehot.scatter_(1, targets.view(-1, 1), 1)\n",
        "\n",
        "                batch = (inputs, targets_onehot)\n",
        "\n",
        "                self.meta_update(batch, K, N)"
      ],
      "metadata": {
        "id": "w4pkXoKfyddH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Omniglot dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataset = Omniglot(root='./data', download=True, background=True, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Initialize MAML\n",
        "model = SimpleModel()\n",
        "maml = MAML(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAJGfBN_ybwP",
        "outputId": "5d6328e3-7e51-4236-b91d-7c186a6b4a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train MAML for multiple epochs\n",
        "for epoch in range(5):\n",
        "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/5\"):\n",
        "        inputs, targets = batch\n",
        "        # Flatten the targets\n",
        "        targets_flat = targets.view(-1)\n",
        "        maml.meta_update((inputs, targets_flat), K=5, N=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "9iHBLClwzBvw",
        "outputId": "a84118cc-4418-4bc1-ea02-3396b3681060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5:   0%|          | 0/19280 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1a42f7733553>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Flatten the targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtargets_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-d471b3bdb880>\u001b[0m in \u001b[0;36mmeta_update\u001b[0;34m(self, batch, K, N)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mmodel_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    }
  ]
}